---
title: "ground-based-model"
output: html_document
date: "2023-12-24"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
## Set the working direcotry using R render syntax
##setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
```

## Load all packages and remove all objects from memory

```{r}
rm(list = ls())
gc()
```

```{r Load packages, warn=FALSE, message=FALSE}
library(rpart.plot)
library(tidyverse)
library(tidymodels)
library(vip)
library(tictoc)
source('./src/spatial-utils.R')
```

## Set the seed for reproducibility

```{r Set the seed}
set.seed(8675309)
```

## Extract all pixels 

If the data is not generated run 'src/sample-all-pixels.R' to extract pixel data from all 50 photographs using the labeled polygons


You can use the function `extract_polygon_pixels` to extract the pixels from the polygons. The function takes three arguments: the path to the image or a polygon sf object, the path to the polygons, and a boolean to include the polygon data. The function returns a list of data frames with the pixels from the polygons. 

```{r}
extract_polygon_pixels
```


```{r Read in data}
pixels_path <- 'clean_data/labeled_pixels.rds'

clean_pixels <- readRDS(pixels_path) |>
  group_by(key) |>
  slice_sample(n = 1000) |>
  ungroup()

clean_pixels
```

## Create training and testing set

```{r Create test train split}
pixel_split <- clean_pixels |>
  dplyr::select(-c(cell))|>
  mutate(label = as.factor(label)) |>
  group_initial_split(prop = 0.75, group = key)

pixels_train <- pixel_split |>
  training()

pixels_test <- pixel_split |>
  testing()
```

## XGBoost model

First we build the formula with all the predictors

```{r Build formula}
all_columns <- names(clean_pixels) |>
  sample(size =  110)
non_predictors <- c("cell", "train_val", "label", "directory", "poly_num", "key", "label", "area")
predictors <- all_columns[!all_columns %in% non_predictors]

formula <- as.formula(paste("label ~", paste(predictors, collapse = " + ")))
#formula <- as.formula(paste("label ~ hsv_1"))
formula
```

We have hundreds of predictors so we fit a single decision tree to get the top 20 layers.

```{r}
tree_rec  <- recipe(formula, data = pixels_train) |>
  step_naomit(all_predictors()) |>
  step_novel(all_nominal_predictors()) |>
  step_dummy(all_nominal_predictors()) |>
  step_zv(all_predictors()) |>
  step_normalize(all_predictors())

tree_spec <- decision_tree() |>
  set_egine("rpart") |>
  set_mode("classification") |>
  set_args(cost_complexity = tune())

tree_wf <- workflow() |>
  add_model(tree_spec) |>
  add_recipe(tree_rec)

tree_grid <- grid_regular(cost_complexity(range = c(-10, -1)), levels = 20)
```

Tune the decision tree

```{r}
pixel_folds <- pixels_train |>
  group_vfold_cv(v = 10, group = key, balance = "observations")

tic()
doParallel::registerDoParallel(15)
tune_res <- tune_grid(
  tree_wf,
  resamples = pixel_folds,
  grid = tree_grid,
  control = control_grid(verbose = TRUE)
)
toc()
```

Visualize tuning results

```{r}
tune_res |>
  autoplot(metric = "accuracy") +
  theme_minimal()
```

```{r}
tree_best <- tune_res |>
  select_by_one_std_err(desc(cost_complexity), metric = "accuracy")

tree_final <- tree_wf |>
  finalize_workflow(tree_best)

tree_fit <- tree_final |>
  fit(data = pixels_train)

# with usual 0.5 threshold
tree_fit |>
  augment(new_data = pixels_test) |>
  conf_mat(truth = label, estimate = .pred_class)


importance <- tree_fit |>
  extract_fit_parsnip() |>
  vip(num_features = 15)
importance
```

```{r}
tree_fit |>
  extract_fit_engine() |>
  rpart.plot(box.palette = list("gray80", "darkolivegreen3", "gold2"), tweak = 0.5)
```

Next, create a tidyverse recipe, specification, workflow, and grid of parameters to tune in the xgboost model. We just use the top 15 important features from the previous built tree

```{r}
top_features <- importance$data$Variable
formula_top_features <- as.formula(paste("label ~", paste(top_features, collapse = " + ")))
formula_top_features
```

```{r Tidymdodels workflow}
xgb_recipe  <- recipe(formula, data = pixels_train) |>
  step_naomit(all_predictors()) |>
  step_novel(all_nominal_predictors()) |>
  step_dummy(all_nominal_predictors()) |>
  step_zv(all_predictors()) |>
  step_normalize(all_predictors())

xgb_specification <- boost_tree(
  trees = 750,
  mtry = tune(),
  min_n = tune(),
  tree_depth = tune(),
  learn_rate = tune(),
  loss_reduction = tune(),
  sample_size = tune()
) |>
  set_engine("xgboost", nthread = 5) |>
  set_mode("classification")

xgb_workflow <- workflow() |>
  add_model(xgb_specification) |>
  add_recipe(xgb_recipe)

prepped_recipe <- prep(xgb_recipe)
baked_recipe <- bake(prepped_recipe, new_data = NULL)

xgb_grid <- grid_latin_hypercube(
  finalize(mtry(),baked_recipe),
  min_n(),
  tree_depth(),
  learn_rate(),
  loss_reduction(),
  sample_size = sample_prop(),
  size = 12
)
```

## Create folds for K fold cross validation

```{r K-Fold Cross validation}
pixel_folds <- pixels_train |>
  group_vfold_cv(v = 10, group = key, balance = "observations")
```

Try nthread = 3 or 4 as an option in set_engine. Then try registerDoParallel(8) or 6. If runs out of memeory use more threads and fewer forks.

Can also try racing methods to really speed things up.

```{r, Tune parameter grid}
tic()
doParallel::registerDoParallel(15)
tune_results <- tune_grid(
  xgb_workflow,
  resamples = pixel_folds,
  grid = xgb_grid,
  control = control_grid(verbose = TRUE)
)
toc()
```

Tuning results

```{r Results}
tune_results |>
  collect_metrics() |>
  filter(.metric == "accuracy") |>
  pivot_longer(mtry:sample_size, names_to = "parameter", values_to = "value") |>
  rename(accuracy = mean) |>
  ggplot(aes(value, accuracy, color = parameter)) +
  geom_point(show.legend = FALSE) +
  facet_wrap(~ parameter, scales = "free_x") +
  theme_minimal()
```

Train the model with best hyperparmeters based on accuracy and then calculate testing error.

```{r}
xgb_best <- tune_results |>
  select_best(metric = "accuracy")

xgb_final <- xgb_workflow |>
  finalize_workflow(xgb_best)

xgb_fit <- xgb_final |>
  fit(data = pixels_train)
```

```{r Save best fit}
saveRDS(xgb_fit, 'clean_data/xgb_fit.rds')
```

Confusion matrix on the test set

```{r}
# 0.5 threshold
confusion_matrix <- xgb_fit |>
  augment(new_data = pixels_test) |>
  conf_mat(truth = label, estimate = .pred_class)

confusion_matrix
```

Accuracy on the test set

```{r}
accuracy <- sum(diag(confusion_matrix$table)) / sum(confusion_matrix$table)
accuracy
```

Find the top features

```{r}
xgb_fit |>
  extract_fit_engine() |>
  vip(num_features = 25) +
  theme_minimal()
```
